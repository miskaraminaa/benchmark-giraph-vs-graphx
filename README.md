# Benchmark Big Data : Apache Giraph vs Spark GraphX & Int√©gration Neo4j

![Big Data](https://img.shields.io/badge/Big%20Data-Project-blue) ![Docker](https://img.shields.io/badge/Docker-Compose-green) ![Spark](https://img.shields.io/badge/Apache-Spark%20GraphX-orange) ![Giraph](https://img.shields.io/badge/Apache-Giraph-red) ![Neo4j](https://img.shields.io/badge/Neo4j-GraphDB-lightgrey)

Ce d√©p√¥t contient l'impl√©mentation compl√®te et le rapport d'un projet d'√©tude comparative entre deux frameworks majeurs de traitement de graphes distribu√©s : **Apache Giraph** (mod√®le BSP) et **Apache Spark GraphX** (mod√®le RDD).

Le projet inclut √©galement une cha√Æne de traitement moderne utilisant **Neo4j** pour le stockage et **Apache Zeppelin** pour l'analyse interactive, le tout orchestr√© via **Docker**.

## üìã Objectifs

1.  Mettre en ≈ìuvre une architecture distribu√©e pour l'analyse de grands graphes.
2.  Comparer les performances (temps d'ex√©cution) de l'algorithme **PageRank**.
3.  Analyser la coh√©sion du r√©seau via **Connected Components** et **Triangle Count**.

## üóÇÔ∏è Dataset

* **Source** : SNAP (Stanford Network Analysis Project)
* **Nom** : [Wiki-Vote](https://snap.stanford.edu/data/wiki-Vote.html)
* **M√©triques** : 7 115 n≈ìuds, 103 689 ar√™tes orient√©es.

---

# Architecture du Projet

L‚Äôarchitecture est divis√©e en deux workflows principaux, tous deux conteneuris√©s via **Docker** afin de garantir une ex√©cution locale reproductible.

---

## Workflow 1 : Neo4j + Spark GraphX + Zeppelin

### Stockage
- **Neo4j** comme base de donn√©es de graphes native (NoSQL).
- Utilisation de **Cypher** pour les op√©rations CRUD et les travers√©es de graphes.

### Traitement analytique
- **Spark GraphX** pour :
  - Charger le graphe depuis Neo4j.
  - Le transformer en **RDD**.
  - Ex√©cuter des algorithmes it√©ratifs tels que **PageRank**, **Connected Components** et **Triangle Count**.

### Interface
- **Apache Zeppelin** pour :
  - Cr√©er des notebooks interactifs.
  - Configurer les d√©pendances.
  - Charger et explorer les donn√©es (ex. : distribution des degr√©s).
  - Visualiser les r√©sultats analytiques.

### √âtapes cl√©s
- Mise en place de **Docker Compose** (services : Neo4j, Spark Master, Spark Worker, Zeppelin).
- Import du dataset **Wiki-Vote** au format CSV dans Neo4j via Cypher.
- Connexion de Spark √† Neo4j pour charger le graphe en **DataFrame/RDD**.
- Analyse exploratoire et ex√©cution des algorithmes avec **benchmarking**.

---

## Workflow 2 : Hadoop + Apache Giraph

### Infrastructure
- **Cluster Hadoop** avec **HDFS** pour le stockage distribu√©.

### Traitement
- **Apache Giraph** pour l‚Äôex√©cution it√©rative de **PageRank** en mode *vertex-centric* (impl√©mentation en Java).

### √âtapes cl√©s
- Int√©gration d‚Äôun cluster **Hadoop + Giraph** dans Docker.
- Export du graphe **Wiki-Vote** vers **HDFS** au format texte (liste d‚Äôar√™tes).
- Ex√©cution du job PageRank avec une configuration sp√©cifique (supersteps, m√©triques).
- Analyse des r√©sultats (logs, timers, compteurs MapReduce).
- Visualisation interactive des r√©sultats via **Zeppelin**.

---

## R√©seau et conteneurisation
- Interconnexion de tous les services via un r√©seau Docker d√©di√© (**graph-network**).
- Utilisation de volumes persistants pour les donn√©es (ex. : `./neo4j-data:/data`).
- Plugins Neo4j :
  - **APOC**
  - **Graph Data Science** pour des fonctionnalit√©s avanc√©es.

---

## Dataset
- **Wiki-Vote** : graphe orient√© repr√©sentant des votes sur Wikipedia.
- Pr√©par√© au format **CSV**, import√© dans **Neo4j**, puis export√© vers **HDFS** pour le traitement avec **Giraph**.


---
# √âtude Comparative

## Performances
- **Spark GraphX** est plus rapide et interactif pour des graphes de taille modeste.
- **Apache Giraph** excelle en **scalabilit√©** pour des graphes tr√®s volumineux (jusqu‚Äô√† des trillions d‚Äôar√™tes).
- Temps d‚Äôex√©cution de **PageRank** sur le dataset *Wiki-Vote* :
  - Giraph : ~13,7 s (incluant l‚Äôoverhead du cluster).
  - Spark : baseline plus rapide pour ce cas d‚Äôusage.

## Mod√®les de programmation
- **Data-centric** (Spark GraphX).
- **Vertex-centric** (Giraph).
- Spark offre une meilleure **exp√©rience d√©veloppeur**, notamment pour l‚Äôanalyse exploratoire et le prototypage rapide.

## Synth√®se
Le choix de la technologie d√©pend du cas d‚Äôusage :
- **Interactivit√© et analyse exploratoire** ‚Üí Spark GraphX.
- **Puissance brute et tr√®s grande √©chelle** ‚Üí Apache Giraph.

---

# Perspectives

- Extension √† des **datasets de plus grande taille**.
- Int√©gration d‚Äô**autres algorithmes** de graphes (ex. : *Community Detection*).
- D√©ploiement sur un **cluster cloud** afin d‚Äô√©valuer la scalabilit√© r√©elle.


## üöÄ Installation et D√©marrage

### Pr√©requis
* Docker & Docker Compose install√©s sur la machine.
* 4 Go de RAM minimum allou√©s √† Docker.

### 1. Cloner le d√©p√¥t
```bash
git clone [https://github.com/miskaraminaa/benchmark-giraph-vs-graphx.git](https://github.com/miskaraminaa/benchmark-giraph-vs-graphx.git)
cd benchmark-giraph-vs-graphx
